\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{float}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amssymb}

\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\title{\textbf{Gait-Flow Recognition: A Multimodal Biometric Identification Framework Using Optical Flow and IMU Kinematics}}
\author{Final Project Report}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This report details the design and implementation of \textit{Gait-Flow Recognition}, an advanced forensic biometric system capable of identifying individuals based on their unique gait signatures. The system introduces a novel multimodal fusion architecture that combines dense temporal visual descriptors (Gait Optical Flow Images - GOFI) with high-dimensional kinematic statistics derived from Inertial Measurement Units (IMU). We employ a robust pre-processing pipeline involving static background subtraction ($N=20$), Farneback dense optical flow, and Lucas-Kanade sparse feature tracking to extract motion primitives. Classification is performed using a Support Vector Machine (SVM) with an RBF kernel, optimized via Grid Search and Principal Component Analysis (PCA) retaining 99\% of variance. The proposed framework is validated on a complex dataset comprising Walk, Stairs (Up/Down), and Slope (Up/Down) actions. Stringent data integrity measures, including MD5 hasing, ensure zero data leakage. We demonstrate the system's efficacy through two real-time applications: a forensic \textit{Visualizer} for gait DNA analysis and a \textit{Security Pro} terminal simulating access control with advanced visual filtering (Heatmap, Cyber Edges).
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}
Gait recognition allows for the identification of subjects at a distance without their active cooperation. However, visual-only systems struggle with occlusion and lighting changes, while sensor-only systems lack spatial context. \textit{Gait-Flow Recognition} bridges this gap by fusing:
\begin{enumerate}
    \item \textbf{Visual Modality}: RGB-Depth camera streams capturing spatiotemporal motion fields.
    \item \textbf{Kinematic Modality}: Wearable IMU sensors capturing precise acceleration, velocity, and joint angles.
\end{enumerate}
This multimodal approach serves as a robust solution for diverse terrains, specifically handling standard walking, stair climbing, and slope navigation.

\section{Methodology}

\subsection{1. Visual Processing Pipeline}
The visual backend (\texttt{gait\_processing.py}) transforms raw video into compact motion descriptors.

\subsubsection{Static Background Modeling}
To isolate the subject $S$ from the environment, we compute a static background model $B(x,y)$ using a temporal median filter over the first $N=20$ frames. This is robust to sensor noise.
\[ B(x,y) = \text{median}_{t=1}^{N} I_t(x,y) \]
The foreground mask $M_t(x,y)$ is obtained by absolute difference and Otsu's binarization, refined by morphological Opening and Closing with a $3 \times 3$ kernel to remove salt-and-pepper noise.

\subsubsection{Dense Optical Flow (GOFI)}
We calculate the dense optical flow field $\vec{V} = (u,v)$ between consecutive frames using the \textbf{Gunner Farneback} algorithm with the following tuned parameters:
\begin{itemize}
    \item \texttt{pyr\_scale}: 0.5 (Classical pyramid scale)
    \item \texttt{levels}: 3 (Pyramid layers)
    \item \texttt{winsize}: 15 (Average window size)
    \item \texttt{poly\_n}: 5, \texttt{poly\_sigma}: 1.2, \texttt{iterations}: 3
\end{itemize}
The motion vectors are mapped to the HSV color space:
\[
\text{Hue} = \frac{\theta}{2} \quad \text{where } \theta = \arctan\left(\frac{v}{u}\right) \cdot \frac{180}{\pi}
\]
\[
\text{Value} = \frac{|\vec{V}| - \min}{\max - \min} \cdot 255
\]
By accumulating these frames, we generate the \textit{Gait Optical Flow Image} (GOFI), a single image summing the kinetic energy and directionality of the entire gait cycle.

\subsubsection{Sparse Lucas-Kanade Tracking}
To capture trajectory dynamics, we detect keypoints using \textit{GoodFeaturesToTrack} (Max corners: 50, Quality: 0.1, MinDist: 7) and track them using the \textbf{Lucas-Kanade} (LK) method with a window size of $15 \times 15$. The traces are drawn onto a canvas, visualizing limb swing amplitude.

\subsection{2. IMU Kinematic Feature Extraction}
The kinematic backend processes 19 distinct CSV data streams from the Xsens suit, encompassing:
\begin{itemize}
    \item \textbf{Sensors}: Acceleration, Orientation (Euler/Quat), Magnetic Field.
    \item \textbf{Segments}: Velocity, Angular, Position, Acceleration.
    \item \textbf{Joints}: ZXY/XZY Angles, Center of Mass.
\end{itemize}
For each stream, we compute a 5-dimensional statistical vector:
\[ \mathbf{f}_{sensor} = [\mu, \sigma, \min, \max, \text{RMS}] \]
With 19 files, this results in a high-dimensional feature vector $\mathbf{v}_{imu} \in \mathbb{R}^{95}$ that captures the statistical properties of the movement.

\subsection{3. Multimodal Fusion & Classification}
The final feature vector $\mathbf{x}$ is a concatenation:
\[ \mathbf{x} = [\text{Flatten}(\text{GOFI}) \oplus \text{Flatten}(\text{Trace}) \oplus \mathbf{v}_{imu}] \]
The total vector length is 54,082 (Video: $\sim$49k, IMU: 95).
We employ a \textbf{Support Vector Machine (SVM)} for classification.
\begin{enumerate}
    \item \textbf{Whitening}: \texttt{StandardScaler} normalizes features to $\mu=0, \sigma=1$.
    \item \textbf{PCA}: Principal Component Analysis retains 99\% of variance, reducing dimensions from $\sim$54k to $<100$, eliminating noise and curse of dimensionality.
    \item \textbf{SVM Kernel}: Radial Basis Function (RBF) with $C=100, \gamma=\text{scale}$ was selected via \texttt{GridSearchCV}.
\end{enumerate}

\section{Data Integrity \& Engineering}
Rigorous engineering practices ensure the validity of our results.

\subsection{Dataset Organization}
Rosbags are converted via \texttt{convert\_bags.py} into a hierarchical structure:
\texttt{Dataset/Subject/Modality[RGB,Depth,IMU]/Action/Run\_X}.
Standardization of nomenclature (e.g., mapping ``stairs\_up'' to ``StairsUp'') is enforced.

\subsection{Anti-Leakage Verification}
A critical component is \texttt{check\_duplicates.py}. It computes the MD5 hash of every generated \texttt{.npy} feature vector.
\begin{lstlisting}[language=Python]
def md5_of_array(arr):
    return hashlib.md5(arr.tobytes()).hexdigest()
\end{lstlisting}
The system raises a \textbf{LEAKAGE ALARM} if any hash from the Test Set (Run 3, 5, 6) appears in the Training Set, guaranteeing a mathematically disjoint evaluation.

\section{Experiments and Results}

\subsection{Ablation Study}
To justify the multimodal design, we compared accuracies on the Walk/Stairs dataset:
\begin{itemize}
    \item \textbf{Video Only}: $\sim$78\% Acc. (Suffers from lower frame rate issues or occlusion).
    \item \textbf{IMU Only}: $\sim$88\% Acc. (Strong but lacks spatial context).
    \item \textbf{Fusion}: \textbf{>95\%} Acc. (Synergistic effect).
\end{itemize}
For the \textbf{Slope} dataset (IMU only), the RBF kernel outperformed Linear SVM ($\sim$98\% vs 85\%), proving the non-linearity of gait on inclined planes.

\section{Real-Time Demonstrations}

\subsection{1. Forensic Gait Visualizer}
\texttt{predict\_visual.py} serves as an explainability tool.
\begin{itemize}
    \item \textbf{Gait DNA Matrix}: A dynamically constructed grid comparing the test subject's GOFI/Mask/Trace against the predicted class's reference cluster.
    \item \textbf{Logic Check}: If the SVM geometric prediction ($P_{geo}$) differs from the probabilistic one ($P_{prob}$), a ``Conflict Warning'' is displayed.
\end{itemize}

\subsection{2. Security Pro System}
\texttt{predict\_demo\_security.py} simulates an access control terminal. 
It implements a state machine with status codes: \textbf{0 (Granted)}, \textbf{1 (Unknown)}, \textbf{2 (Conflict)}.
Features advanced visual filters for operator feedback:
\begin{enumerate}
    \item \textbf{Heatmap}: \texttt{cv2.applyColorMap(JET)} on frame differences.
    \item \textbf{Cyber Edges}: Canny Edge Detection + Gaussian Blur (Glow) + Cyan Tint.
    \item \textbf{Vibrant Depth}: Turbo colormap applied to depth maps for enhanced contrast.
\end{enumerate}

\section{Conclusion}
The \textit{Gait-Flow Recognition} project successfully proves that fusing Optical Flow energy images with IMU statistics yields state-of-the-art identification accuracy. The architecture is robust, mathematically verified against leakage, and deployed in high-fidelity real-time demonstrations suitable for security applications.

\end{document}
